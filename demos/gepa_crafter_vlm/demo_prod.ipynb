{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": [
    "# Crafter VLM GEPA Demo\n",
    "\n",
    "This demo runs GEPA prompt optimization for a Crafter vision-language agent that uses image-only observations.\n",
    "\n",
    "**What this demo does:**\n",
    "1. Creates a local task app for the Crafter VLM agent\n",
    "2. Runs GEPA prompt optimization to find the best system prompt\n",
    "3. Extracts the optimized prompt from results\n",
    "4. Runs eval jobs comparing baseline vs optimized prompts\n",
    "5. Displays comparison results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-1",
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": "# Parameters (can be overridden by papermill)\nBACKEND_URL = \"https://api.usesynth.ai\"  # Default to production\nAPI_KEY = None  # Will be set based on environment\nPOLICY_MODEL = \"gpt-4.1-nano\"  # VLM model for the agent\nVERIFIER_MODEL = \"gpt-5-nano\"  # Model for verification (must be in allowed list)\nROLLOUT_BUDGET = 30  # Total rollout budget\nNUM_GENERATIONS = 2  # Number of GEPA generations\nUSE_TUNNEL = True  # Whether to use cloudflared tunnels (required for prod)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-2",
   "metadata": {},
   "outputs": [],
   "source": "# Step 1: Imports and Setup\nfrom __future__ import annotations\n\nimport asyncio\nimport json\nimport os\nimport sys\nimport time\nfrom pathlib import Path\nfrom typing import Any, Dict, List, Optional\n\nimport httpx\nfrom dotenv import load_dotenv\nfrom openai import AsyncOpenAI\n\nload_dotenv()\n\n# Add parent directory to path for imports\nsys.path.insert(0, str(Path('.').resolve().parent.parent))\n\nfrom synth_ai.sdk.api.eval import EvalJob, EvalJobConfig\nfrom synth_ai.sdk.api.train.prompt_learning import PromptLearningJob\nfrom synth_ai.sdk.learning.prompt_learning_client import PromptLearningClient\nfrom synth_ai.sdk.learning.rl import mint_environment_api_key, setup_environment_api_key\nfrom synth_ai.sdk.localapi import LocalAPIConfig, create_local_api\nfrom synth_ai.sdk.task import TaskInfo, run_server_background\nfrom synth_ai.sdk.task.contracts import RolloutMetrics, RolloutRequest, RolloutResponse\nfrom synth_ai.sdk.tunnels import wait_for_health_check\nfrom synth_ai.sdk.tunnels.tunneled_api import TunneledLocalAPI, TunnelBackend\n\nfrom crafter_logic import (\n    ACTION_STRING_TO_INT,\n    CRAFTER_ALLOWED_ACTIONS,\n    CrafterEnvironmentWrapper,\n    CrafterScorer,\n    CrafterVLMReActPolicy,\n    normalize_action_name,\n)\n\nprint('Imports loaded successfully')"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Configuration\n",
    "\n",
    "SYNTH_API_BASE = 'https://api.usesynth.ai'\n",
    "LOCAL_API_PORT = 8001\n",
    "OPTIMIZED_LOCAL_API_PORT = 8002\n",
    "\n",
    "print(f'Backend: {SYNTH_API_BASE}')\n",
    "print(f'Local API Ports: {LOCAL_API_PORT}, {OPTIMIZED_LOCAL_API_PORT}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Get API Key and Check Backend Health\n",
    "\n",
    "if API_KEY:\n",
    "    SYNTH_API_KEY = API_KEY\n",
    "else:\n",
    "    SYNTH_API_KEY = os.environ.get('SYNTH_API_KEY', '').strip()\n",
    "\n",
    "if not SYNTH_API_KEY:\n",
    "    raise RuntimeError('SYNTH_API_KEY not set. Please set it in environment or pass as parameter.')\n",
    "\n",
    "print(f'Using API Key: {SYNTH_API_KEY[:20]}...')\n",
    "\n",
    "# Check backend health\n",
    "r = httpx.get(f'{SYNTH_API_BASE}/health', timeout=30)\n",
    "if r.status_code == 200:\n",
    "    print(f'Backend health: {r.json()}')\n",
    "else:\n",
    "    raise RuntimeError(f'Backend not healthy: status {r.status_code}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-6",
   "metadata": {},
   "outputs": [],
   "source": "# Step 5: Local API Factory\n\nAPP_ID = \"crafter_vlm\"\nAPP_NAME = \"Crafter VLM ReAct Agent\"\nTOOL_NAME = \"crafter_interact\"\n\ndef create_crafter_vlm_local_api(system_prompt: str, env_api_key: str):\n    \"\"\"Factory to create a Crafter VLM task app with a specific system prompt.\"\"\"\n    # Import inside factory to ensure availability in closure\n    from crafter_logic import (\n        ACTION_STRING_TO_INT,\n        CRAFTER_ALLOWED_ACTIONS,\n        CrafterEnvironmentWrapper,\n        CrafterScorer,\n        CrafterVLMReActPolicy,\n        normalize_action_name,\n    )\n    \n    os.environ['ENVIRONMENT_API_KEY'] = env_api_key\n\n    async def run_rollout(request: RolloutRequest, fastapi_request) -> RolloutResponse:\n        policy_config = request.policy.config or {}\n        seed = request.env.seed or 0\n        env_config = request.env.config or {}\n        max_steps = int(env_config.get('max_steps_per_episode', 200))\n        max_turns = int(env_config.get('max_turns', 50))\n\n        env = CrafterEnvironmentWrapper(seed=seed, max_steps=max_steps)\n        observation = await env.reset()\n\n        policy = CrafterVLMReActPolicy(\n            system_prompt=system_prompt,\n            use_vision=True,\n            image_only_mode=True,\n        )\n\n        # Route OpenAI calls through Synth's inference proxy for trace reconstruction\n        inference_url = policy_config.get('inference_url', '')\n        if inference_url:\n            os.environ['OPENAI_BASE_URL'] = inference_url\n        \n        # Use policy_config api_key (from Synth proxy) or fall back to OPENAI_API_KEY env var\n        api_key = policy_config.get('api_key') or os.environ.get('OPENAI_API_KEY')\n        if not api_key:\n            raise ValueError(\"No API key available: policy_config['api_key'] and OPENAI_API_KEY env var are both empty\")\n        client = AsyncOpenAI(api_key=api_key)\n\n        history: List[Dict[str, Any]] = []\n        episode_rewards: List[float] = []\n\n        for turn in range(max_turns):\n            messages = policy.build_messages(observation, history)\n            \n            response = await client.chat.completions.create(\n                model=policy_config.get('model', POLICY_MODEL),\n                messages=messages,\n                tools=policy.tools,\n                tool_choice='required',\n                max_completion_tokens=policy_config.get('max_completion_tokens', 512),\n            )\n            \n            message = response.choices[0].message\n            response_text = message.content or ''\n            tool_calls = [\n                {'id': tc.id, 'type': 'function', 'function': {'name': tc.function.name, 'arguments': tc.function.arguments}}\n                for tc in (message.tool_calls or [])\n            ]\n\n            next_observation = observation\n            tool_responses: List[Dict[str, Any]] = []\n            \n            if tool_calls:\n                for tc in tool_calls:\n                    tool_call_id = tc['id']\n                    tool_name = tc['function']['name']\n                    actions_list: List[str] = []\n                    \n                    if tool_name == TOOL_NAME:\n                        try:\n                            args = json.loads(tc['function']['arguments'])\n                            raw_actions = args.get('actions_list', [])\n                            actions_list = [str(a) for a in raw_actions if str(a).strip()][:5]\n                        except Exception:\n                            pass\n                    \n                    if not actions_list:\n                        actions_list = ['noop']\n\n                    normalized_actions = []\n                    action_results = []\n\n                    for action_str in actions_list:\n                        normalized = normalize_action_name(action_str) or 'noop'\n                        normalized_actions.append(normalized)\n                        action = ACTION_STRING_TO_INT.get(normalized, 0)\n                        next_observation = await env.step(action)\n                        reward = next_observation.get('reward', 0.0)\n                        episode_rewards.append(float(reward))\n                        action_results.append({\n                            'action': normalized,\n                            'reward': reward,\n                            'terminated': next_observation.get('terminated'),\n                            'truncated': next_observation.get('truncated'),\n                        })\n                        if next_observation.get('terminated') or next_observation.get('truncated'):\n                            break\n\n                    tool_responses.append({'tool_call_id': tool_call_id, 'actions': normalized_actions, 'results': action_results})\n                    if next_observation.get('terminated') or next_observation.get('truncated'):\n                        break\n            else:\n                next_observation = await env.step(0)\n                episode_rewards.append(float(next_observation.get('reward', 0.0)))\n\n            history.append({'role': 'assistant', 'content': response_text, 'tool_calls': tool_calls})\n            for resp in tool_responses:\n                history.append({\n                    'role': 'tool',\n                    'tool_call_id': resp['tool_call_id'],\n                    'content': json.dumps({'actions': resp['actions'], 'results': resp['results']}),\n                })\n\n            observation = next_observation\n            if observation.get('terminated') or observation.get('truncated'):\n                break\n\n        score, details = CrafterScorer.score_episode(observation, len(episode_rewards), max_steps)\n\n        return RolloutResponse(\n            run_id=request.run_id,\n            metrics=RolloutMetrics(outcome_reward=score, details=details),\n            trace=None,  # Synth reconstructs from inference proxy\n            trace_correlation_id=policy_config.get('trace_correlation_id'),\n        )\n\n    def provide_taskset_description():\n        return {'splits': ['train', 'test']}\n\n    def provide_task_instances(seeds):\n        for seed in seeds:\n            yield TaskInfo(\n                task={'id': APP_ID, 'name': APP_NAME},\n                dataset={'id': APP_ID, 'split': 'train', 'index': seed},\n                inference={'tool': TOOL_NAME},\n                limits={'max_turns': 50},\n                task_metadata={'seed': seed},\n            )\n\n    return create_local_api(LocalAPIConfig(\n        app_id=APP_ID,\n        name=APP_NAME,\n        description=f'{APP_NAME} local API for VLM agent with image-only observations.',\n        provide_taskset_description=provide_taskset_description,\n        provide_task_instances=provide_task_instances,\n        rollout=run_rollout,\n        cors_origins=['*'],\n    ))\n\n\nprint('Local API factory defined')"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-7",
   "metadata": {},
   "outputs": [],
   "source": "# Step 6: GEPA Job Runner\n\ndef run_gepa_job(\n    *,\n    api_key: str,\n    local_api_url: str,\n    local_api_key: str,\n    baseline_system_prompt: str,\n):\n    \"\"\"Run a GEPA prompt optimization job.\"\"\"\n    config_body = {\n        'prompt_learning': {\n            'algorithm': 'gepa',\n            'task_app_url': local_api_url,\n            'task_app_api_key': local_api_key,\n            'env_name': 'crafter',\n            'initial_prompt': {\n                'messages': [{'role': 'system', 'order': 0, 'pattern': baseline_system_prompt}],\n                'wildcards': {},\n            },\n            'policy': {\n                'inference_mode': 'synth_hosted',\n                'model': POLICY_MODEL,\n                'provider': 'openai',\n                'temperature': 0.0,\n                'max_completion_tokens': 512,\n            },\n            'gepa': {\n                'env_name': 'crafter',\n                'evaluation': {'seeds': list(range(30)), 'validation_seeds': list(range(50, 56))},\n                'rollout': {'budget': ROLLOUT_BUDGET, 'max_concurrent': 3, 'minibatch_size': 3},\n                'mutation': {'rate': 0.3},\n                'population': {'initial_size': 3, 'num_generations': NUM_GENERATIONS, 'children_per_generation': 2},\n                'archive': {'size': 5, 'pareto_set_size': 10},\n                'token': {'max_limit': 4000, 'counting_model': 'gpt-4', 'max_spend_usd': 50.0},\n            },\n            'env': {\n                'max_turns': 20,  # Cap VLM calls per rollout\n                'max_steps_per_episode': 200,\n            },\n            'verifier': {\n                'enabled': False,\n                'reward_source': 'task_app',\n            },\n        },\n    }\n\n    job = PromptLearningJob.from_dict(\n        config_dict=config_body,\n        backend_url=SYNTH_API_BASE,\n        api_key=api_key,\n        task_app_api_key=local_api_key,\n        skip_health_check=True,\n    )\n    job_id = job.submit()\n    print(f'GEPA job created: {job_id}')\n    \n    result = job.poll_until_complete(timeout=3600.0, interval=3.0, progress=True)\n    print(f'GEPA job finished: {result.status.value}')\n    return result\n\n\nprint('GEPA job runner defined')"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-8",
   "metadata": {},
   "outputs": [],
   "source": "# Step 7: Eval Job Runner\n\nEVAL_MODEL = \"gpt-4o-mini\"  # Use real OpenAI model for eval (eval doesn't support synth_hosted)\nOPENAI_API_KEY = os.environ.get('OPENAI_API_KEY', '')  # Get OpenAI key for eval jobs\n\ndef run_eval_job(*, local_api_url: str, local_api_key: str, seeds: list[int], mode: str):\n    \"\"\"Run an eval job and wait for completion.\"\"\"\n    config = EvalJobConfig(\n        task_app_url=local_api_url,\n        backend_url=SYNTH_API_BASE,\n        api_key=SYNTH_API_KEY,\n        task_app_api_key=local_api_key,\n        env_name='crafter',\n        seeds=seeds,\n        policy_config={\n            'model': EVAL_MODEL,\n            'provider': 'openai',\n            'api_key': OPENAI_API_KEY,  # Pass OpenAI key to task app\n        },\n        env_config={\n            'max_steps_per_episode': 200,\n            'max_turns': 20,\n        },\n        concurrency=5,\n    )\n    job = EvalJob(config)\n    job_id = job.submit()\n    print(f'  {mode} eval job: {job_id}')\n    return job.poll_until_complete(timeout=600.0, interval=2.0, progress=True)\n\n\nprint('Eval job runner defined')"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 8: Setup Environment API Key\n",
    "\n",
    "environment_api_key = mint_environment_api_key()\n",
    "os.environ['ENVIRONMENT_API_KEY'] = environment_api_key\n",
    "print(f'Minted: {environment_api_key[:12]}...{environment_api_key[-4:]}')\n",
    "\n",
    "try:\n",
    "    setup_environment_api_key(SYNTH_API_BASE, SYNTH_API_KEY, token=environment_api_key)\n",
    "    print('Environment API key uploaded')\n",
    "except Exception as exc:\n",
    "    print(f'Warning: failed to upload ENVIRONMENT_API_KEY: {exc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 9: Define Baseline Prompt\n",
    "\n",
    "allowed_actions = ', '.join(CRAFTER_ALLOWED_ACTIONS)\n",
    "baseline_prompt = (\n",
    "    'You are an agent playing Crafter, a survival crafting game. '\n",
    "    'Your goal is to survive and unlock achievements by exploring, crafting, and building. '\n",
    "    'You can see the game state through images. Analyze each image carefully to understand '\n",
    "    'your surroundings, inventory, health, and available resources. '\n",
    "    'Use the crafter_interact tool to execute actions. '\n",
    "    \"Key mechanics: use 'do' only when adjacent to a resource (tree, stone, cow, plant); \"\n",
    "    'it does nothing on grass or water. '\n",
    "    'Craft progression: wood -> table -> wood_pickaxe -> stone -> stone_pickaxe -> iron tools. '\n",
    "    'Sleep when energy is low to restore and unlock wake_up. '\n",
    "    f'Available actions: {allowed_actions}. '\n",
    "    'Only use these action names and return 2-5 actions per decision. '\n",
    "    'Strategy: move toward trees to collect wood; place a table once you have wood; '\n",
    "    'craft a wood pickaxe, then collect stone and craft a stone pickaxe; '\n",
    "    'progress toward iron tools and combat when safe.'\n",
    ")\n",
    "\n",
    "print('Baseline prompt:')\n",
    "print(baseline_prompt[:200] + '...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-11",
   "metadata": {},
   "outputs": [],
   "source": "# Step 10: Start Baseline Local API\n\nbaseline_app = create_crafter_vlm_local_api(baseline_prompt, environment_api_key)\nrun_server_background(baseline_app, port=LOCAL_API_PORT)\nawait wait_for_health_check('127.0.0.1', LOCAL_API_PORT, environment_api_key, timeout=60.0)\n\nif USE_TUNNEL:\n    # Create tunnel to expose local API to the internet\n    print(f'Creating tunnel for port {LOCAL_API_PORT}...')\n    baseline_tunnel = await TunneledLocalAPI.create(\n        local_port=LOCAL_API_PORT,\n        backend=TunnelBackend.CloudflareManagedTunnel,\n        api_key=SYNTH_API_KEY,\n        env_api_key=environment_api_key,\n        backend_url=SYNTH_API_BASE,\n        progress=True,\n    )\n    BASELINE_LOCAL_API_URL = baseline_tunnel.url\nelse:\n    BASELINE_LOCAL_API_URL = f'http://localhost:{LOCAL_API_PORT}'\n\nprint(f'Baseline local API URL: {BASELINE_LOCAL_API_URL}')"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 11: Run GEPA Optimization\n",
    "\n",
    "print('Starting GEPA optimization...')\n",
    "print(f'  Rollout budget: {ROLLOUT_BUDGET}')\n",
    "print(f'  Generations: {NUM_GENERATIONS}')\n",
    "\n",
    "job_result = run_gepa_job(\n",
    "    api_key=SYNTH_API_KEY,\n",
    "    local_api_url=BASELINE_LOCAL_API_URL,\n",
    "    local_api_key=environment_api_key,\n",
    "    baseline_system_prompt=baseline_prompt,\n",
    ")\n",
    "\n",
    "print(f'\\nGEPA Status: {job_result.status.value}')\n",
    "if job_result.succeeded:\n",
    "    print('GEPA optimization succeeded!')\n",
    "else:\n",
    "    print(f'GEPA failed: {job_result.error}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 12: Extract Optimized Prompt\n",
    "\n",
    "def extract_system_prompt(best_prompt: Optional[Dict[str, Any]]) -> Optional[str]:\n",
    "    \"\"\"Extract system prompt from prompt learning results.\"\"\"\n",
    "    if not best_prompt:\n",
    "        return None\n",
    "    for msg in best_prompt.get('messages', []):\n",
    "        if msg.get('role') == 'system':\n",
    "            return msg.get('pattern') or msg.get('content')\n",
    "    for sec in best_prompt.get('sections', []):\n",
    "        if sec.get('role') == 'system':\n",
    "            return sec.get('content')\n",
    "    return None\n",
    "\n",
    "optimized_prompt = None\n",
    "\n",
    "if job_result.succeeded:\n",
    "    pl_client = PromptLearningClient(SYNTH_API_BASE, SYNTH_API_KEY)\n",
    "    prompt_results = await pl_client.get_prompts(job_result.job_id)\n",
    "    optimized_prompt = extract_system_prompt(prompt_results.best_prompt)\n",
    "    \n",
    "    if optimized_prompt:\n",
    "        print('=' * 60)\n",
    "        print('OPTIMIZED PROMPT')\n",
    "        print('=' * 60)\n",
    "        print(optimized_prompt[:800] + '...' if len(optimized_prompt) > 800 else optimized_prompt)\n",
    "        print('=' * 60)\n",
    "        \n",
    "        # Save to results directory\n",
    "        results_dir = Path('results')\n",
    "        results_dir.mkdir(exist_ok=True)\n",
    "        with open(results_dir / 'optimized_prompt.txt', 'w') as f:\n",
    "            f.write(optimized_prompt)\n",
    "        print(f'\\nSaved optimized prompt to: {results_dir / \"optimized_prompt.txt\"}')\n",
    "    else:\n",
    "        print('Failed to extract optimized prompt from results')\n",
    "else:\n",
    "    print('Skipping prompt extraction (GEPA did not succeed)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-14",
   "metadata": {},
   "outputs": [],
   "source": "# Step 13: Run Evaluation (Baseline vs Optimized)\n\nEVAL_SEEDS = list(range(100, 120))  # 20 held-out test samples\n\nif optimized_prompt:\n    # Start optimized local API\n    optimized_app = create_crafter_vlm_local_api(optimized_prompt, environment_api_key)\n    run_server_background(optimized_app, port=OPTIMIZED_LOCAL_API_PORT)\n    await wait_for_health_check('127.0.0.1', OPTIMIZED_LOCAL_API_PORT, environment_api_key, timeout=60.0)\n    \n    if USE_TUNNEL:\n        # Create tunnel for optimized API\n        print(f'Creating tunnel for port {OPTIMIZED_LOCAL_API_PORT}...')\n        optimized_tunnel = await TunneledLocalAPI.create(\n            local_port=OPTIMIZED_LOCAL_API_PORT,\n            backend=TunnelBackend.CloudflareManagedTunnel,\n            api_key=SYNTH_API_KEY,\n            env_api_key=environment_api_key,\n            backend_url=SYNTH_API_BASE,\n            progress=True,\n        )\n        OPTIMIZED_LOCAL_API_URL = optimized_tunnel.url\n    else:\n        OPTIMIZED_LOCAL_API_URL = f'http://localhost:{OPTIMIZED_LOCAL_API_PORT}'\n    \n    print(f'Optimized local API URL: {OPTIMIZED_LOCAL_API_URL}')\n    print(f'\\nRunning evaluation on {len(EVAL_SEEDS)} seeds...')\n\n    # Run baseline eval\n    print('\\nRunning BASELINE eval...')\n    baseline_eval = run_eval_job(\n        local_api_url=BASELINE_LOCAL_API_URL,\n        local_api_key=environment_api_key,\n        seeds=EVAL_SEEDS,\n        mode='baseline',\n    )\n\n    # Run optimized eval\n    print('\\nRunning OPTIMIZED eval...')\n    optimized_eval = run_eval_job(\n        local_api_url=OPTIMIZED_LOCAL_API_URL,\n        local_api_key=environment_api_key,\n        seeds=EVAL_SEEDS,\n        mode='optimized',\n    )\n\n    # Display results\n    print('\\n' + '=' * 60)\n    print('EVALUATION RESULTS')\n    print('=' * 60)\n    print(f'Baseline: {baseline_eval.raw}')\n    print(f'Optimized: {optimized_eval.raw}')\n    \n    # Save results\n    results_dir = Path('results')\n    results_dir.mkdir(exist_ok=True)\n    with open(results_dir / 'eval_results.json', 'w') as f:\n        json.dump({'baseline': baseline_eval.raw, 'optimized': optimized_eval.raw}, f, indent=2)\n    print(f'\\nSaved eval results to: {results_dir / \"eval_results.json\"}')\nelse:\n    print('Skipping evaluation (no optimized prompt)')"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 14: Done\n",
    "print('Demo complete!')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}