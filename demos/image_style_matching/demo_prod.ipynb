{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Style Matching Demo\n",
    "\n",
    "This demo uses GraphGen to optimize a workflow for generating Pokemon-style images.\n",
    "\n",
    "**What this demo does:**\n",
    "1. Creates a dataset with Pokemon-style image generation tasks\n",
    "2. Runs GraphGen optimization to find the best prompt workflow\n",
    "3. Downloads the optimized graph and runs inference\n",
    "4. Saves generated images to the results folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# Parameters (can be overridden by papermill)\n",
    "BACKEND_URL = None  # Will be set based on environment\n",
    "API_KEY = None  # Will be set based on environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Step 1: Imports and Setup\nimport os\nimport sys\nimport json\nimport base64\nimport uuid\nfrom pathlib import Path\n\nimport httpx\nfrom dotenv import load_dotenv\n\nload_dotenv()\n\n# Add parent directory to path for imports\nsys.path.insert(0, str(Path('.').resolve().parent.parent))\n\nfrom synth_ai.sdk.api.train.graphgen import GraphGenJob, load_graphgen_taskset\nfrom synth_ai.sdk.graphs.completions import GraphCompletionsSyncClient\n\nprint('Imports loaded successfully')"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Configure Backend\n",
    "\n",
    "# Use parameter if provided, otherwise check environment\n",
    "if BACKEND_URL:\n",
    "    SYNTH_API_BASE = BACKEND_URL\n",
    "elif os.environ.get('LOCAL_BACKEND', '').lower() in ('1', 'true', 'yes'):\n",
    "    SYNTH_API_BASE = 'http://127.0.0.1:8000/api'\n",
    "else:\n",
    "    SYNTH_API_BASE = os.environ.get('BACKEND_BASE_URL') or 'https://api.usesynth.ai'\n",
    "    if not SYNTH_API_BASE.endswith('/api'):\n",
    "        SYNTH_API_BASE = SYNTH_API_BASE.rstrip('/') + '/api'\n",
    "\n",
    "print(f'Backend: {SYNTH_API_BASE}')\n",
    "\n",
    "# Check backend health\n",
    "r = httpx.get(f'{SYNTH_API_BASE}/health', timeout=30)\n",
    "if r.status_code == 200:\n",
    "    print(f'Backend health: {r.json()}')\n",
    "else:\n",
    "    raise RuntimeError(f'Backend not healthy: status {r.status_code}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Get API Key\n",
    "\n",
    "# Use parameter if provided, otherwise check environment\n",
    "if API_KEY:\n",
    "    SYNTH_API_KEY = API_KEY\n",
    "else:\n",
    "    SYNTH_API_KEY = os.environ.get('SYNTH_API_KEY', '')\n",
    "\n",
    "if not SYNTH_API_KEY:\n",
    "    print('No SYNTH_API_KEY found, minting demo key...')\n",
    "    resp = httpx.post(f'{SYNTH_API_BASE}/api/demo/keys', json={'ttl_hours': 4}, timeout=30)\n",
    "    resp.raise_for_status()\n",
    "    SYNTH_API_KEY = resp.json()['api_key']\n",
    "    print(f'Demo API Key: {SYNTH_API_KEY[:25]}...')\n",
    "else:\n",
    "    print(f'Using API Key: {SYNTH_API_KEY[:20]}...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Step 4: Create Dataset\n\ndef _load_gold_image(filename: str) -> str:\n    \"\"\"Load a Pokemon image from gold_images folder as base64 data URL.\"\"\"\n    img_path = Path(\"gold_images\") / filename\n    with open(img_path, \"rb\") as f:\n        img_data = f.read()\n    return f\"data:image/png;base64,{base64.b64encode(img_data).decode('ascii')}\"\n\n# Define tasks with matching gold images\ntasks = [\n    {\"id\": \"pokemon_dragon\", \"input\": {\"subject\": \"dragon\", \"style\": \"pokemon\", \"description\": \"A dragon creature in Pokemon art style\"}},\n    {\"id\": \"pokemon_cat\", \"input\": {\"subject\": \"cat\", \"style\": \"pokemon\", \"description\": \"A cat creature in Pokemon art style\"}},\n    {\"id\": \"pokemon_bird\", \"input\": {\"subject\": \"bird\", \"style\": \"pokemon\", \"description\": \"A bird creature in Pokemon art style\"}},\n]\n\n# Load real Pokemon reference images\ngold_image_files = [\"charizard_dragon.png\", \"meowth_cat.png\", \"pidgeot_bird.png\"]\ngold_outputs = [\n    {\"task_id\": task[\"id\"], \"output\": {\"image_url\": _load_gold_image(gold_image_files[i]), \"note\": f\"Reference for {task['input']['subject']}\"}}\n    for i, task in enumerate(tasks)\n]\n\n# Define schemas\ninput_schema = {\n    \"type\": \"object\",\n    \"properties\": {\"subject\": {\"type\": \"string\"}, \"style\": {\"type\": \"string\"}, \"description\": {\"type\": \"string\"}},\n    \"required\": [\"subject\", \"style\", \"description\"]\n}\noutput_schema = {\n    \"type\": \"object\",\n    \"properties\": {\"image_url\": {\"type\": \"string\", \"description\": \"Base64-encoded image data URL\"}},\n    \"required\": [\"image_url\"]\n}\n\n# Create dataset\nunique_id = uuid.uuid4().hex[:8]\ndataset = {\n    \"version\": \"1.0\",\n    \"metadata\": {\n        \"name\": f\"pokemon-style-matching-{unique_id}\",\n        \"description\": \"Pokemon art style matching with contrastive VLM judge.\",\n        \"input_schema\": input_schema,\n        \"output_schema\": output_schema,\n    },\n    \"initial_prompt\": \"Generate an image.\",\n    \"tasks\": tasks,\n    \"gold_outputs\": gold_outputs,\n    \"input_schema\": input_schema,\n    \"output_schema\": output_schema,\n    \"default_rubric\": {\n        \"outcome\": {\n            \"criteria\": [\n                {\"name\": \"pokemon_style_match\", \"description\": \"Image matches Pokemon art style\", \"weight\": 1.0},\n                {\"name\": \"subject_recognition\", \"description\": \"Subject is recognizable\", \"weight\": 0.8},\n                {\"name\": \"visual_quality\", \"description\": \"Image is high quality\", \"weight\": 0.5},\n            ]\n        }\n    },\n    \"judge_config\": {\"mode\": \"contrastive\", \"model\": \"gpt-4.1-nano\", \"provider\": \"openai\"}\n}\n\n# Save dataset\ndataset_path = Path(\"image_style_matching_dataset.json\")\nwith open(dataset_path, \"w\") as f:\n    json.dump(dataset, f, indent=2)\n\nprint(f'Created dataset: {dataset[\"metadata\"][\"name\"]}')\nprint(f'  Tasks: {len(tasks)}, Gold outputs: {len(gold_outputs)}')\nprint(f'  Gold images: {gold_image_files}')\nprint(f'  Judge: {dataset[\"judge_config\"][\"mode\"]} with {dataset[\"judge_config\"][\"model\"]}')"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Run GraphGen Optimization\n",
    "\n",
    "dataset_obj = load_graphgen_taskset(dataset_path)\n",
    "\n",
    "problem_spec = (\n",
    "    \"Generate images that match Pokemon art style. \"\n",
    "    \"Use Gemini for image generation and a VLM judge for style matching.\"\n",
    ")\n",
    "\n",
    "print('Creating GraphGen job...')\n",
    "job = GraphGenJob.from_dataset(\n",
    "    dataset=dataset_obj,\n",
    "    policy_model=\"gemini-2.5-flash-image\",  # Image generation model\n",
    "    rollout_budget=10,\n",
    "    proposer_effort=\"medium\",\n",
    "    population_size=2,\n",
    "    num_generations=1,\n",
    "    problem_spec=problem_spec,\n",
    "    backend_url=SYNTH_API_BASE,\n",
    "    api_key=SYNTH_API_KEY,\n",
    "    auto_start=True,\n",
    ")\n",
    "\n",
    "print(f'  Policy model: {job.config.policy_model}')\n",
    "print(f'  Rollout budget: {job.config.rollout_budget}')\n",
    "\n",
    "result = job.submit()\n",
    "print(f'\\nJob submitted: {result.graphgen_job_id}')\n",
    "\n",
    "# Poll until complete\n",
    "final_status = job.poll_until_complete(timeout=600.0, interval=5.0, progress=True)\n",
    "\n",
    "print(f'\\nFINAL STATUS: {final_status.get(\"status\")}')\n",
    "if final_status.get(\"status\") == \"succeeded\":\n",
    "    print(f'BEST SCORE: {final_status.get(\"best_score\")}')\n",
    "elif final_status.get(\"status\") == \"failed\":\n",
    "    print(f'ERROR: {final_status.get(\"error\")}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 6: Download Optimized Graph\n",
    "\n",
    "if final_status.get(\"status\") == \"succeeded\":\n",
    "    print('=' * 60)\n",
    "    print('OPTIMIZED GRAPH')\n",
    "    print('=' * 60)\n",
    "    \n",
    "    graph_txt = job.download_graph_txt()\n",
    "    print(graph_txt)\n",
    "    \n",
    "    # Save graph\n",
    "    results_dir = Path(\"results\")\n",
    "    results_dir.mkdir(exist_ok=True)\n",
    "    \n",
    "    with open(results_dir / \"optimized_graph.txt\", \"w\") as f:\n",
    "        f.write(graph_txt)\n",
    "    print(f'\\nSaved graph to: {results_dir / \"optimized_graph.txt\"}')\n",
    "else:\n",
    "    print(f'Job did not succeed: {final_status.get(\"status\")}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Step 7: Run Inference and Save Images\n\ndef save_image_from_data_url(data_url: str, output_path: Path) -> bool:\n    \"\"\"Save a base64 data URL to an image file.\"\"\"\n    if not data_url.startswith(\"data:image\"):\n        return False\n    header, encoded = data_url.split(\",\", 1)\n    with open(output_path, \"wb\") as f:\n        f.write(base64.b64decode(encoded))\n    return True\n\nif final_status.get(\"status\") == \"succeeded\":\n    results_dir = Path(\"results\")\n    results_dir.mkdir(exist_ok=True)\n    \n    # Create typed sync client for graph completions\n    graph_client = GraphCompletionsSyncClient(\n        base_url=SYNTH_API_BASE,\n        api_key=SYNTH_API_KEY,\n        timeout=180.0,  # Image generation can take 2-3 minutes\n    )\n    \n    job_id = result.graphgen_job_id\n    \n    test_inputs = [\n        {\"subject\": \"wolf\", \"style\": \"pokemon\", \"description\": \"A wolf creature in Pokemon art style\"},\n        {\"subject\": \"fox\", \"style\": \"pokemon\", \"description\": \"A fox creature in Pokemon art style\"},\n        {\"subject\": \"rabbit\", \"style\": \"pokemon\", \"description\": \"A rabbit creature in Pokemon art style\"},\n    ]\n    \n    print(f'Running inference on {len(test_inputs)} test inputs...')\n    print(f'Job ID: {job_id}\\n')\n    \n    for i, test_input in enumerate(test_inputs):\n        print(f'Test {i+1}: {test_input[\"subject\"]}')\n        try:\n            # Use typed sync client\n            response = graph_client.run(job_id=job_id, input_data=test_input)\n            print(f'  Cache: {response.cache_status or \"unknown\"}')\n            \n            # Find image in output\n            nested = response.output\n            image_url = None\n            \n            # Check node outputs\n            for key, val in nested.items():\n                if key.endswith(\"_output\") and isinstance(val, dict) and \"image_url\" in val:\n                    candidate = val[\"image_url\"]\n                    if isinstance(candidate, str) and len(candidate) > 5000:\n                        image_url = candidate\n                        print(f'  Found image in {key}: {len(image_url)} chars')\n                        break\n            \n            if not image_url:\n                candidate = nested.get(\"image_url\", \"\")\n                if isinstance(candidate, str) and len(candidate) > 5000:\n                    image_url = candidate\n            \n            # Save image\n            if image_url:\n                img_path = results_dir / f\"test_{i+1}_{test_input['subject']}.png\"\n                if save_image_from_data_url(image_url, img_path):\n                    print(f'  Saved: {img_path}')\n            else:\n                print(f'  No valid image found')\n                \n        except Exception as e:\n            print(f'  Error: {e}')\n    \n    print(f'\\nResults saved to: {results_dir}')\nelse:\n    print('Skipping inference (job did not succeed)')"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleanup temporary dataset file\n",
    "if dataset_path.exists():\n",
    "    dataset_path.unlink()\n",
    "    print(f'Cleaned up: {dataset_path}')\n",
    "\n",
    "print('\\nDemo complete!')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}