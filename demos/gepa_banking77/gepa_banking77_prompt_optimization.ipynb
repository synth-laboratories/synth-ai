{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": [
    "# Synth GEPA Demo - Banking77\n",
    "\n",
    "Prompt optimization using Synth's GEPA algorithm on the Banking77 intent classification task.\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/synth-laboratories/synth-ai/blob/main/demos/gepa_banking77/gepa_banking77_prompt_optimization.ipynb)\n",
    "\n",
    "**Structure:**\n",
    "1. **Setup** - Install dependencies and configure\n",
    "2. **Task Definition** - Banking77 classification task\n",
    "3. **Local API** - Expose the task for optimization\n",
    "4. **Optimize** - Run GEPA to discover better prompts\n",
    "5. **Evaluate** - Formal eval on held-out data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35ku8p0wn7",
   "metadata": {},
   "outputs": [],
   "source": "import sys\n\nif \"google.colab\" in sys.modules:\n    import subprocess\n    import os\n\n    print(\"Installing dependencies...\")\n    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", \"--no-deps\", \"synth-ai\"])\n    subprocess.check_call([\n        sys.executable, \"-m\", \"pip\", \"install\", \"-q\",\n        \"nest_asyncio\", \"openai\", \"httpx\", \"pydantic\", \"rich\", \"tqdm\",\n        \"aiohttp\", \"pynacl\", \"fastapi\", \"uvicorn\", \"python-dotenv\"\n    ])\n\n    if not os.path.exists(\"/usr/local/bin/cloudflared\"):\n        subprocess.check_call([\n            \"wget\", \"-q\",\n            \"https://github.com/cloudflare/cloudflared/releases/latest/download/cloudflared-linux-amd64\",\n            \"-O\", \"/usr/local/bin/cloudflared\",\n        ])\n        os.chmod(\"/usr/local/bin/cloudflared\", 0o755)\n\n    print(\"Done!\")"
  },
  {
   "cell_type": "markdown",
   "id": "setup-md",
   "metadata": {},
   "source": [
    "## Step 1: Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-setup",
   "metadata": {},
   "outputs": [],
   "source": "import json\nimport os\n\nimport nest_asyncio\nfrom datasets import load_dataset\nfrom synth_ai.core.env import PROD_BASE_URL, mint_demo_api_key\n\nnest_asyncio.apply()\n\nAPI_KEY = mint_demo_api_key()\nos.environ[\"SYNTH_API_KEY\"] = API_KEY\nSYNTH_API_BASE = PROD_BASE_URL\n\nprint(f\"API Key: {API_KEY[:20]}...\")"
  },
  {
   "cell_type": "markdown",
   "id": "biz-logic-md",
   "metadata": {},
   "source": [
    "## Step 2: Task Definition\n",
    "\n",
    "Banking77 is an intent classification task with 77 possible intents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-biz-logic",
   "metadata": {},
   "outputs": [],
   "source": [
    "BANKING77_LABELS = [\n",
    "    \"activate_my_card\",\n",
    "    \"age_limit\",\n",
    "    \"apple_pay_or_google_pay\",\n",
    "    \"atm_support\",\n",
    "    \"automatic_top_up\",\n",
    "    \"balance_not_updated_after_bank_transfer\",\n",
    "    \"balance_not_updated_after_cheque_or_cash_deposit\",\n",
    "    \"beneficiary_not_allowed\",\n",
    "    \"cancel_transfer\",\n",
    "    \"card_about_to_expire\",\n",
    "    \"card_acceptance\",\n",
    "    \"card_arrival\",\n",
    "    \"card_delivery_estimate\",\n",
    "    \"card_linking\",\n",
    "    \"card_not_working\",\n",
    "    \"card_payment_fee_charged\",\n",
    "    \"card_payment_not_recognised\",\n",
    "    \"card_payment_wrong_exchange_rate\",\n",
    "    \"card_swallowed\",\n",
    "    \"cash_withdrawal_charge\",\n",
    "    \"cash_withdrawal_not_recognised\",\n",
    "    \"change_pin\",\n",
    "    \"compromised_card\",\n",
    "    \"contactless_not_working\",\n",
    "    \"country_support\",\n",
    "    \"declined_card_payment\",\n",
    "    \"declined_cash_withdrawal\",\n",
    "    \"declined_transfer\",\n",
    "    \"direct_debit_payment_not_recognised\",\n",
    "    \"disposable_card_limits\",\n",
    "    \"edit_personal_details\",\n",
    "    \"exchange_charge\",\n",
    "    \"exchange_rate\",\n",
    "    \"exchange_via_app\",\n",
    "    \"extra_charge_on_statement\",\n",
    "    \"failed_transfer\",\n",
    "    \"fiat_currency_support\",\n",
    "    \"get_disposable_virtual_card\",\n",
    "    \"get_physical_card\",\n",
    "    \"getting_spare_card\",\n",
    "    \"getting_virtual_card\",\n",
    "    \"lost_or_stolen_card\",\n",
    "    \"lost_or_stolen_phone\",\n",
    "    \"order_physical_card\",\n",
    "    \"passcode_forgotten\",\n",
    "    \"pending_card_payment\",\n",
    "    \"pending_cash_withdrawal\",\n",
    "    \"pending_top_up\",\n",
    "    \"pending_transfer\",\n",
    "    \"pin_blocked\",\n",
    "    \"receiving_money\",\n",
    "    \"Refund_not_showing_up\",\n",
    "    \"request_refund\",\n",
    "    \"reverted_card_payment?\",\n",
    "    \"supported_cards_and_currencies\",\n",
    "    \"terminate_account\",\n",
    "    \"top_up_by_bank_transfer_charge\",\n",
    "    \"top_up_by_card_charge\",\n",
    "    \"top_up_by_cash_or_cheque\",\n",
    "    \"top_up_failed\",\n",
    "    \"top_up_limits\",\n",
    "    \"top_up_reverted\",\n",
    "    \"topping_up_by_card\",\n",
    "    \"transaction_charged_twice\",\n",
    "    \"transfer_fee_charged\",\n",
    "    \"transfer_into_account\",\n",
    "    \"transfer_not_received_by_recipient\",\n",
    "    \"transfer_timing\",\n",
    "    \"unable_to_verify_identity\",\n",
    "    \"verify_my_identity\",\n",
    "    \"verify_source_of_funds\",\n",
    "    \"verify_top_up\",\n",
    "    \"virtual_card_not_working\",\n",
    "    \"visa_or_mastercard\",\n",
    "    \"why_verify_identity\",\n",
    "    \"wrong_amount_of_cash_received\",\n",
    "    \"wrong_exchange_rate_for_cash_withdrawal\",\n",
    "]\n",
    "\n",
    "TOOL_NAME = \"banking77_classify\"\n",
    "TOOL_SCHEMA = {\n",
    "    \"type\": \"function\",\n",
    "    \"function\": {\n",
    "        \"name\": TOOL_NAME,\n",
    "        \"description\": \"Return the predicted banking77 intent label.\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\"intent\": {\"type\": \"string\"}},\n",
    "            \"required\": [\"intent\"],\n",
    "        },\n",
    "    },\n",
    "}\n",
    "\n",
    "\n",
    "def format_available_intents(labels: list) -> str:\n",
    "    return \"\\n\".join(f\"{i + 1}. {label}\" for i, label in enumerate(labels))\n",
    "\n",
    "\n",
    "dataset = load_dataset(\"banking77\", split=\"test\", trust_remote_code=False)\n",
    "label_names = dataset.features[\"label\"].names\n",
    "print(f\"Loaded {len(dataset)} samples, {len(label_names)} intents\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "local-api-md",
   "metadata": {},
   "source": [
    "## Step 3: Local API\n",
    "\n",
    "Expose the task via HTTP so Synth can run optimization against it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-local-api",
   "metadata": {},
   "outputs": [],
   "source": [
    "from synth_ai.sdk.localapi import LocalAPIConfig, create_local_api\n",
    "from synth_ai.sdk.task.contracts import RolloutMetrics, RolloutRequest, RolloutResponse, TaskInfo\n",
    "from synth_ai.sdk.tunnels import TunnelBackend, TunneledLocalAPI\n",
    "\n",
    "BASELINE_SYSTEM_PROMPT = \"\"\"You are an expert banking assistant that classifies customer queries into banking intents. Given a customer message, respond with exactly one intent label from the provided list using the `banking77_classify` tool.\"\"\"\n",
    "\n",
    "USER_PROMPT = \"Customer Query: {query}\\n\\nAvailable Intents:\\n{available_intents}\\n\\nClassify this query into one of the above banking intents using the tool call.\"\n",
    "\n",
    "\n",
    "class Banking77Dataset:\n",
    "    def __init__(self):\n",
    "        self._cache = {}\n",
    "        self._label_names = None\n",
    "\n",
    "    def _load_split(self, split: str):\n",
    "        if split not in self._cache:\n",
    "            ds = load_dataset(\"banking77\", split=split, trust_remote_code=False)\n",
    "            self._cache[split] = ds\n",
    "            if self._label_names is None:\n",
    "                self._label_names = ds.features[\"label\"].names\n",
    "        return self._cache[split]\n",
    "\n",
    "    def size(self, split: str) -> int:\n",
    "        return len(self._load_split(split))\n",
    "\n",
    "    def sample(self, *, split: str, index: int) -> dict:\n",
    "        ds = self._load_split(split)\n",
    "        row = ds[index % len(ds)]\n",
    "        return {\n",
    "            \"index\": index % len(ds),\n",
    "            \"split\": split,\n",
    "            \"text\": row[\"text\"],\n",
    "            \"label\": self._label_names[row[\"label\"]],\n",
    "        }\n",
    "\n",
    "\n",
    "def create_banking77_local_api(system_prompt: str):\n",
    "    ds = Banking77Dataset()\n",
    "    ds._load_split(\"train\")\n",
    "    ds._load_split(\"test\")\n",
    "\n",
    "    async def run_rollout(request: RolloutRequest, fastapi_request) -> RolloutResponse:\n",
    "        sample = ds.sample(\n",
    "            split=request.env.config.get(\"split\", \"train\"),\n",
    "            index=request.env.seed,\n",
    "        )\n",
    "\n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": f\"Customer Query: {sample['text']}\\n\\nAvailable Intents:\\n{format_available_intents(BANKING77_LABELS)}\\n\\nClassify this query into one of the above banking intents using the tool call.\",\n",
    "            },\n",
    "        ]\n",
    "\n",
    "        from openai import AsyncOpenAI\n",
    "\n",
    "        client = AsyncOpenAI(\n",
    "            base_url=f\"{SYNTH_API_BASE}/api/openai/v1\",\n",
    "            api_key=API_KEY,\n",
    "        )\n",
    "        response = await client.chat.completions.create(\n",
    "            model=request.policy.config.get(\"model\", \"gpt-4.1-nano\"),\n",
    "            messages=messages,\n",
    "            tools=[TOOL_SCHEMA],\n",
    "            tool_choice={\"type\": \"function\", \"function\": {\"name\": TOOL_NAME}},\n",
    "        )\n",
    "\n",
    "        predicted = json.loads(response.choices[0].message.tool_calls[0].function.arguments)[\n",
    "            \"intent\"\n",
    "        ]\n",
    "        expected = sample[\"label\"]\n",
    "        reward = (\n",
    "            1.0\n",
    "            if predicted.lower().replace(\"_\", \" \") == expected.lower().replace(\"_\", \" \")\n",
    "            else 0.0\n",
    "        )\n",
    "\n",
    "        return RolloutResponse(\n",
    "            run_id=request.run_id,\n",
    "            metrics=RolloutMetrics(outcome_reward=reward),\n",
    "            trace=None,\n",
    "        )\n",
    "\n",
    "    def provide_taskset_description():\n",
    "        return {\n",
    "            \"splits\": [\"train\", \"test\"],\n",
    "            \"sizes\": {\"train\": ds.size(\"train\"), \"test\": ds.size(\"test\")},\n",
    "        }\n",
    "\n",
    "    def provide_task_instances(seeds):\n",
    "        for seed in seeds:\n",
    "            sample = ds.sample(split=\"train\", index=seed)\n",
    "            yield TaskInfo(\n",
    "                task={\"id\": \"banking77\", \"name\": \"Banking77\"},\n",
    "                dataset={\"id\": \"banking77\", \"split\": sample[\"split\"], \"index\": sample[\"index\"]},\n",
    "                inference={\"tool\": TOOL_NAME},\n",
    "                limits={\"max_turns\": 1},\n",
    "                task_metadata={\"query\": sample[\"text\"], \"expected_intent\": sample[\"label\"]},\n",
    "            )\n",
    "\n",
    "    return create_local_api(\n",
    "        LocalAPIConfig(\n",
    "            app_id=\"banking77\",\n",
    "            name=\"Banking77\",\n",
    "            description=\"Banking77 intent classification\",\n",
    "            provide_taskset_description=provide_taskset_description,\n",
    "            provide_task_instances=provide_task_instances,\n",
    "            rollout=run_rollout,\n",
    "            cors_origins=[\"*\"],\n",
    "        )\n",
    "    )\n",
    "\n",
    "\n",
    "print(\"Starting local API...\")\n",
    "baseline_app = create_banking77_local_api(BASELINE_SYSTEM_PROMPT)\n",
    "\n",
    "baseline_tunnel = await TunneledLocalAPI.create_for_app(\n",
    "    app=baseline_app,\n",
    "    local_port=None,\n",
    "    backend=TunnelBackend.CloudflareManagedTunnel,\n",
    "    progress=True,\n",
    ")\n",
    "BASELINE_LOCAL_API_URL = baseline_tunnel.url\n",
    "print(f\"Local API URL: {BASELINE_LOCAL_API_URL}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "gepa-md",
   "metadata": {},
   "source": [
    "## Step 4: Run GEPA\n",
    "\n",
    "GEPA evolves prompts over multiple generations, selecting the best performers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-gepa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from synth_ai.sdk.api.train.prompt_learning import PromptLearningJob\n",
    "\n",
    "config = {\n",
    "    \"prompt_learning\": {\n",
    "        \"algorithm\": \"gepa\",\n",
    "        \"task_app_url\": BASELINE_LOCAL_API_URL,\n",
    "        \"env_name\": \"banking77\",\n",
    "        \"initial_prompt\": {\n",
    "            \"messages\": [\n",
    "                {\"role\": \"system\", \"order\": 0, \"pattern\": BASELINE_SYSTEM_PROMPT},\n",
    "                {\"role\": \"user\", \"order\": 1, \"pattern\": USER_PROMPT},\n",
    "            ],\n",
    "            \"wildcards\": {\"query\": \"REQUIRED\", \"available_intents\": \"OPTIONAL\"},\n",
    "        },\n",
    "        \"policy\": {\n",
    "            \"model\": \"gpt-4.1-nano\",\n",
    "            \"provider\": \"openai\",\n",
    "            \"inference_mode\": \"synth_hosted\",\n",
    "            \"temperature\": 0.0,\n",
    "            \"max_completion_tokens\": 256,\n",
    "        },\n",
    "        \"gepa\": {\n",
    "            \"env_name\": \"banking77\",\n",
    "            \"evaluation\": {\n",
    "                \"seeds\": list(range(50)),\n",
    "                \"validation_seeds\": list(range(50, 60)),\n",
    "            },\n",
    "            \"rollout\": {\"budget\": 80, \"max_concurrent\": 8, \"minibatch_size\": 8},\n",
    "            \"proposer_effort\": \"MEDIUM\",\n",
    "            \"proposer_output_tokens\": \"FAST\",\n",
    "            \"mutation\": {\"rate\": 0.3},\n",
    "            \"population\": {\"initial_size\": 4, \"num_generations\": 3, \"children_per_generation\": 3},\n",
    "            \"archive\": {\"size\": 5, \"pareto_set_size\": 10},\n",
    "        },\n",
    "    },\n",
    "}\n",
    "\n",
    "job = PromptLearningJob.from_dict(config)\n",
    "job_id = job.submit()\n",
    "print(f\"Job ID: {job_id}\")\n",
    "\n",
    "result = job.poll_until_complete(timeout=3600.0, interval=3.0, progress=True)\n",
    "print(f\"\\nStatus: {result.status.value}\")\n",
    "if result.succeeded:\n",
    "    print(f\"Best Score: {result.best_score:.1%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eval-md",
   "metadata": {},
   "source": [
    "## Step 5: Evaluate\n",
    "\n",
    "Compare baseline vs optimized prompts on held-out test samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-eval",
   "metadata": {},
   "outputs": [],
   "source": [
    "from synth_ai.sdk.api.eval import EvalJob, EvalJobConfig\n",
    "from synth_ai.sdk.learning.prompt_learning_client import PromptLearningClient\n",
    "\n",
    "if result.succeeded:\n",
    "    pl_client = PromptLearningClient()\n",
    "    prompt_results = await pl_client.get_prompts(result.job_id)\n",
    "    optimized_prompt = next(\n",
    "        s[\"content\"]\n",
    "        for s in prompt_results.top_prompts[0][\"template\"][\"sections\"]\n",
    "        if s[\"role\"] == \"system\"\n",
    "    )\n",
    "\n",
    "    print(f\"Best training score: {prompt_results.best_score:.1%}\")\n",
    "    print(f\"\\nOptimized prompt:\\n{optimized_prompt[:300]}...\")\n",
    "\n",
    "    optimized_app = create_banking77_local_api(optimized_prompt)\n",
    "    optimized_tunnel = await TunneledLocalAPI.create_for_app(\n",
    "        app=optimized_app,\n",
    "        local_port=None,\n",
    "        backend=TunnelBackend.CloudflareManagedTunnel,\n",
    "        progress=True,\n",
    "    )\n",
    "\n",
    "    EVAL_SEEDS = list(range(100, 150))\n",
    "\n",
    "    def run_eval(url: str, name: str):\n",
    "        job = EvalJob(\n",
    "            EvalJobConfig(\n",
    "                local_api_url=url,\n",
    "                backend_url=SYNTH_API_BASE,\n",
    "                api_key=API_KEY,\n",
    "                env_name=\"banking77\",\n",
    "                seeds=EVAL_SEEDS,\n",
    "                policy_config={\"model\": \"gpt-4.1-nano\", \"provider\": \"openai\"},\n",
    "                env_config={\"split\": \"test\"},\n",
    "                concurrency=10,\n",
    "            )\n",
    "        )\n",
    "        job.submit()\n",
    "        return job.poll_until_complete(timeout=600.0, interval=2.0, progress=True)\n",
    "\n",
    "    print(\"\\nEvaluating baseline...\")\n",
    "    baseline_eval = run_eval(BASELINE_LOCAL_API_URL, \"baseline\")\n",
    "\n",
    "    print(\"\\nEvaluating optimized...\")\n",
    "    optimized_eval = run_eval(optimized_tunnel.url, \"optimized\")\n",
    "\n",
    "    if baseline_eval.succeeded and optimized_eval.succeeded:\n",
    "        lift = optimized_eval.mean_score - baseline_eval.mean_score\n",
    "        print(f\"\\n{'=' * 50}\")\n",
    "        print(f\"Baseline:  {baseline_eval.mean_score:.1%}\")\n",
    "        print(f\"Optimized: {optimized_eval.mean_score:.1%}\")\n",
    "        print(f\"Lift:      {lift:+.1%}\")\n",
    "else:\n",
    "    print(f\"Optimization failed: {result.error}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-cleanup",
   "metadata": {},
   "outputs": [],
   "source": [
    "from synth_ai.sdk.tunnels import cleanup_all\n",
    "\n",
    "cleanup_all()\n",
    "print(\"Done!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "synth-ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}