[job]
model = "Qwen/Qwen3-4B"
data = "tests/artifacts/datasets/crafter_reject_sft.small.jsonl"

[compute]
gpu_type = "H100"
gpu_count = 4
nodes = 1

[data.topology]
container_count = 4
gpus_per_node = 4
total_gpus = 4
nodes = 1

[training]
mode = "full_finetune"
use_qlora = false

[training.validation]
enabled = false
evaluation_strategy = "steps"
eval_steps = 100
save_best_model_at_end = false
metric_for_best_model = "val.loss"
greater_is_better = false

[hyperparameters]
n_epochs = 1
train_kind = "fft"
per_device_batch = 1
gradient_accumulation_steps = 1
sequence_length = 1024
learning_rate = 5e-6
warmup_ratio = 0.03
global_batch = 4

[hyperparameters.parallelism]
fsdp = true
fsdp_sharding_strategy = "full_shard"
fsdp_auto_wrap_policy = "transformer_block"
fsdp_use_orig_params = true
activation_checkpointing = true
tensor_parallel_size = 1
pipeline_parallel_size = 1
bf16 = true
fp16 = false
use_deepspeed = false
