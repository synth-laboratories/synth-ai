
[algorithm]
type = "offline"
method = "sft"
variety = "lora"

[job]
model = "Qwen/Qwen3-VL-2B-Instruct"
data = "/private/var/folders/7b/96hbyfld35zflr_plpgvrdxm0000gn/T/pytest-of-joshpurtell/pytest-68/test_cli_train_sft_vision_smal0/vision_sft_small.jsonl"

[compute]
gpu_type = "H200"
gpu_count = 1

[training]
mode = "lora"
use_qlora = true

[training.validation]
enabled = false

[hyperparameters]
n_epochs = 1
train_kind = "peft"
per_device_batch = 1
gradient_accumulation_steps = 1
sequence_length = 1024
learning_rate = 5e-5
lora_rank = 8
lora_alpha = 16
lora_target_modules = ["q_proj", "v_proj"]

[hyperparameters.parallelism]
bf16 = true
fp16 = false

[model_config]
supports_vision = true
max_images_per_message = 1

[tags]
purpose = "ci_test"
