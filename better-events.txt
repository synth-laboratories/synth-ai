# Better Events Scoping Document

## Goal
Make GEPA event streams rich enough for comprehensive analysis dashboards and demos.
We want to know what events would let us implement an in-depth research report with no shortcuts.

## Target Use Cases

### 1. GEPA for Style Matching
- Style transfer optimization
- Need: prompt content changes, style metrics per candidate

### 2. Banking77 End-to-End Demo
- Intent classification walkthrough
- Need: complete data for blogpost-style analysis

## What the Banking77 Blogpost Needs (Reference)

The blogpost at `docs/cookbooks/gepa-hello-world.mdx` requires:

1. **Baseline Performance**
   - Baseline prompt text (full system + user messages)
   - Baseline accuracy (44%)
   - Per-seed breakdown: which seeds passed/failed
   - Sample failures: query, expected_intent, predicted_intent

2. **All Candidates (13 total)**
   - Each candidate's ID, train_accuracy, val_accuracy
   - Generation number, parent_id
   - Whether it's Pareto optimal
   - instance_scores (per-seed binary scores)
   - The prompt transformation text

3. **Contrastive Examples**
   - For specific seeds (e.g., seed 5, 67, 13, 0):
     - How baseline predicted
     - How each candidate (c0, c1, c3, c7, trans_00013) predicted
     - Which were correct

4. **Failure Mode Analysis**
   - Intent confusion cases
   - Query echoing cases (model outputs query verbatim)
   - Format pollution cases (model outputs "Customer Query" etc.)

5. **Disagreement Analysis**
   - Seeds where baseline and best disagree
   - Which baseline won, which best won
   - Net improvement calculation

6. **Pareto Frontier Evolution**
   - How frontier changed over time
   - Added/removed candidates at each update

7. **Best Candidate Details**
   - Full optimized prompt text
   - Why it's better (structure, disambiguation rules)

## Required Data Points

### Per-Candidate Data (ALL candidates, not just optimized)

**Currently Available:**
- `version_id` - candidate ID
- `accuracy` - aggregate accuracy
- `accepted` - whether accepted to archive
- `generation` - which generation
- `parent_id` - parent candidate

**MISSING - Need to Add:**
- `instance_scores` - per-seed scores (array of 0/1 for each seed)
- `seeds_evaluated` - which seed indices were used
- `prompt_text` or `transformation` - the actual prompt/diff
- `mutation_type` - what kind of mutation was applied
- `rollout_sample` - MAX 3 seeds that expanded Pareto frontier (see constraints below)

**Rollout Sample Constraints:**
- Only include if candidate expanded Pareto frontier (made progress on new seeds)
- Max 3 seeds per event
- Hard limit: 50KB total payload size for rollout_sample
- If ANY single seed exceeds limit, send empty array (don't slow things down)
- Priority: seeds where this candidate uniquely solved (frontier expansion seeds)

### Pareto Frontier Updates

**Currently Available:**
- `frontier` - list of version_ids in frontier
- `added` - newly added to frontier
- `removed` - removed from frontier
- `frontier_size` - count

**MISSING - Need to Add:**
- `frontier_scores` - {version_id: accuracy} for all frontier members
- `optimistic_score` - current optimistic frontier score
- `timestamp_ms` - precise timing for animation

### Validation Phase

**Currently Available:**
- `validation.scored` events with version_id, accuracy

**MISSING - Need to Add:**
- `val_instance_scores` - per-seed validation scores
- `val_seeds` - which validation seeds
- `val_rollout_details` - per-seed: query, expected, predicted

### Confusion Matrix Data

**MISSING - Need to Add:**
- `confusion_matrix` - {predicted: {expected: count}}
- `intent_distribution` - counts per intent in dataset
- `per_intent_accuracy` - accuracy broken down by intent

### Generation-Level Events

**Currently Available:**
- Some generation start/complete events

**MISSING - Need to Add:**
- `prompt.learning.gepa.generation.complete` with:
  - `generation` - generation number
  - `candidates_proposed` - how many proposed
  - `candidates_accepted` - how many accepted
  - `best_accuracy` - best so far
  - `frontier_size` - current frontier size
  - `children` - list of {version_id, parent_id, accuracy, accepted}

### Baseline Data

**Currently Available:**
- `prompt.learning.gepa.baseline` event

**MISSING - Need to Add:**
- `baseline_instance_scores` - per-seed baseline scores
- `baseline_prompt` - full baseline prompt text
- `baseline_seeds` - which seeds baseline was evaluated on
- `baseline_rollout_sample` - MAX 3 failure cases (same constraints as above)

## Event Schema Proposals

### 1. Enhanced `prompt.learning.gepa.candidate.evaluated`

```python
{
    "version_id": "trans_00013",
    "accuracy": 0.815,
    "accepted": true,
    "generation": 5,
    "parent_id": "trans_00008",
    "mutation_type": "text_replacement",

    # NEW FIELDS:
    "instance_scores": [1, 0, 1, 1, 1, 0, 1, 1, 1, 0],  # per-seed
    "seeds_evaluated": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9],
    "prompt_summary": "[TRANSFORMATION] Replace in system...",  # truncated
    "transformation": {
        "text_replacements": [...],
        "example_injections": [...]
    },
    "rollout_sample": [  # MAX 3, only frontier-expanding seeds, 50KB limit
        {"seed": 0, "query": "...", "expected": "card_arrival", "predicted": "card_arrival", "correct": true},
        {"seed": 5, "query": "...", "expected": "card_arrival", "predicted": "card_arrival", "correct": true},
    ]  # empty array if any seed exceeds size limit
}
```

### 2. Enhanced `prompt.learning.gepa.frontier_updated`

```python
{
    "frontier": ["trans_00013", "trans_00008"],
    "added": ["trans_00013"],
    "removed": ["trans_00005"],
    "frontier_size": 2,

    # NEW FIELDS:
    "frontier_scores": {
        "trans_00013": 0.815,
        "trans_00008": 0.78
    },
    "optimistic_score": 0.85,  # max across frontier
    "generation": 5,
    "timestamp_ms": 1701234567890
}
```

### 3. New `prompt.learning.gepa.generation.summary`

```python
{
    "generation": 5,
    "candidates_proposed": 6,
    "candidates_accepted": 2,
    "best_accuracy": 0.815,
    "frontier_size": 4,
    "children": [
        {"version_id": "trans_00013", "parent_id": "trans_00008", "accuracy": 0.815, "accepted": true},
        {"version_id": "trans_00014", "parent_id": "trans_00010", "accuracy": 0.65, "accepted": false},
        ...
    ],
    "duration_ms": 12500
}
```

### 4. Enhanced `prompt.learning.gepa.baseline`

```python
{
    "accuracy": 0.44,

    # NEW FIELDS:
    "instance_scores": [0, 0, 1, 1, 0, 0, 1, 1, 0, 0, ...],
    "seeds_evaluated": [0, 1, 2, 3, 4, 5, ...],
    "prompt": {
        "messages": [
            {"role": "system", "content": "You are an expert..."},
            {"role": "user", "content": "Customer Query: {query}..."}
        ]
    },
    "rollout_sample": [...]  # MAX 3 failure cases, 50KB limit
}
```

### 5. New `prompt.learning.gepa.complete` enhancement

```python
{
    "best_score": 0.815,
    "best_candidate_id": "trans_00013",

    # NEW FIELDS:
    "total_candidates": 13,
    "total_generations": 5,
    "final_frontier": ["trans_00013", "trans_00008"],
    "final_frontier_scores": {"trans_00013": 0.815, "trans_00008": 0.78},
    "baseline_score": 0.44,
    "improvement": 0.375,  # best - baseline
    "confusion_matrix": {
        "card_arrival": {"card_arrival": 80, "card_delivery_estimate": 15, ...},
        ...
    },
    "all_candidates_summary": [
        {"version_id": "trans_00013", "accuracy": 0.815, "generation": 5, "accepted": true},
        {"version_id": "c0", "accuracy": 0.45, "generation": 0, "accepted": false},
        ...
    ]
}
```

## Implementation Plan

### Phase 1: Backend (monorepo)
1. Update `GEPAOptimizer._emit_candidate_evaluated()` to include instance_scores
2. Update `_emit_frontier_updated()` to include frontier_scores
3. Add generation summary emission
4. Enhance baseline event with full data
5. Enhance complete event with summary data

### Phase 2: SDK (synth-ai)
1. Update `PromptLearningJob.stream_events()` to parse enhanced events
2. Add typed dataclasses for each event type
3. Add convenience methods: `job.get_all_candidates()`, `job.get_pareto_history()`, etc.
4. Add `job.to_analysis_dict()` for demo consumption

### Phase 3: Demo Updates (cookbooks)
1. Update banking77 demo to use new event stream
2. Remove manual rollout extraction (get from events)
3. Simplify result saving code

## Questions to Resolve

1. **Bandwidth**: Should rollout_details be opt-in via config flag?
2. **Storage**: How much does this increase event payload size?
3. **Backwards Compat**: Can we add fields without breaking existing consumers?
4. **Validation Phase**: Do we need separate events for validation-phase candidates?

## Files to Modify

### monorepo/backend
- `app/routes/prompt_learning/algorithm/gepa/optimizer.py` - emit enhanced events
- `app/routes/prompt_learning/online_jobs.py` - controller event handling
- `app/routes/prompt_learning/events/types.py` - new event types

### synth-ai
- `synth_ai/sdk/api/train/prompt_learning.py` - event parsing
- `synth_ai/sdk/api/train/events.py` - new event dataclasses (create)
- `synth_ai/sdk/api/train/analysis.py` - analysis helpers (create)

### cookbooks
- `demos/banking77/run_banking77_demo.py` - consume new events

---

# Part 2: Standardized Progress Tracking Helpers

## Problem

Current state is dogshit:
1. `synth_ai/cli/local/experiment_queue/status_tracker.py` - parses regex from stdout
2. `synth_ai/cli/local/experiment_queue/progress_info.py` - dataclass for progress
3. `cookbooks/demos/banking77/run_banking77_demo.py` - ad-hoc Banking77DemoTracker class
4. Various other demos have their own tracking code

Each one:
- Parses events differently
- Tracks different fields
- Has different terminal output formatting
- Breaks when backend event format changes

## Goal

One standardized `GEPAProgressTracker` class that:
1. Consumes SSE events from `PromptLearningJob.stream_events()`
2. Tracks all relevant state
3. Provides rich terminal output (optional, for local dev)
4. Exposes clean API for analysis/reporting
5. Works identically for in-process and remote jobs

## Proposed API

```python
from synth_ai.sdk.api.train.progress import GEPAProgressTracker

# Usage 1: Simple terminal streaming (local dev)
tracker = GEPAProgressTracker(
    show_progress=True,      # Print to terminal
    show_candidates=True,    # Show each candidate as evaluated
    show_pareto=True,        # Show frontier updates
    save_results=True,       # Auto-save to output_dir
    output_dir="./results",
)

async for event in job.stream_events():
    tracker.update(event)  # Handles all event types

# Access final state
tracker.baseline_score       # 0.44
tracker.best_score           # 0.815
tracker.candidates           # List[CandidateInfo]
tracker.pareto_history       # List[FrontierUpdate]
tracker.get_candidate("trans_00013")  # CandidateInfo

# Generate analysis
tracker.to_analysis_dict()   # Full dict for JSON
tracker.save_all("./results")  # Save all files
tracker.print_summary()      # Rich terminal summary

# Usage 2: Headless (no terminal output, just tracking)
tracker = GEPAProgressTracker(show_progress=False)
async for event in job.stream_events():
    tracker.update(event)
results = tracker.to_analysis_dict()
```

## Dataclasses

```python
@dataclass
class CandidateInfo:
    """Info about a single candidate."""
    candidate_id: str
    accuracy: float
    val_accuracy: float | None
    generation: int | None
    parent_id: str | None
    is_pareto: bool
    instance_scores: list[float]  # per-seed scores
    prompt_summary: str | None    # truncated prompt text
    transformation: dict | None   # full transformation if available
    rollout_sample: list[RolloutSample]  # max 3 frontier-expanding seeds
    timestamp: float

@dataclass
class RolloutSample:
    """Sample rollout for a seed."""
    seed: int
    query: str
    expected: str
    predicted: str
    correct: bool

@dataclass
class FrontierUpdate:
    """Pareto frontier update event."""
    timestamp: float
    added: list[str]
    removed: list[str]
    frontier: list[str]
    frontier_scores: dict[str, float]
    optimistic_score: float | None

@dataclass
class BaselineInfo:
    """Baseline prompt info."""
    accuracy: float
    instance_scores: list[float]
    prompt: dict | None
    rollout_sample: list[RolloutSample]

@dataclass
class GEPAProgress:
    """Current progress snapshot."""
    phase: str  # "init", "optimization", "validation", "complete", "failed"
    rollouts_completed: int
    rollouts_total: int
    generations_completed: int
    candidates_evaluated: int
    best_score: float
    elapsed_seconds: float
    eta_seconds: float | None
```

## Terminal Output Format

```
GEPA Optimization - banking77
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
Phase: optimization | Gen 5/20 | Rollouts: 150/500 (30%)
Best: 0.815 (↑0.375 from baseline 0.44) | Frontier: 4 candidates
ETA: 2m 15s | Rate: 45 rollouts/min

Recent:
  ✓ trans_00013  acc=0.815  (new best, +frontier)
  ✓ trans_00012  acc=0.72   (frontier)
  ✗ trans_00011  acc=0.55   (rejected)
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
```

## Files to Create

### synth_ai/sdk/api/train/progress/
- `__init__.py` - exports
- `tracker.py` - GEPAProgressTracker class
- `dataclasses.py` - CandidateInfo, FrontierUpdate, etc.
- `terminal.py` - Terminal output formatting (uses rich)
- `analysis.py` - Analysis helpers (confusion matrix, disagreement, etc.)

## Migration Path

1. Create new `progress/` module in synth-ai
2. Update banking77 demo to use it
3. Update CLI status tracker to use shared dataclasses
4. Deprecate ad-hoc trackers in other demos

---

# Part 3: Tracker Review - What's Good, What Sucks

## Existing Trackers Found

| Location | Class | Status |
|----------|-------|--------|
| `research/run_gepa_banking77_dev.py` | `GEPAProgressTracker` | Best - most complete |
| `research/internal/redactle/run_gepa_in_process.py` | `RedactleProgressTracker` | Copy-paste of above |
| `research/internal/style-matching/run_gepa_in_process.py` | `StyleMatchingProgressTracker` | Copy-paste of above |
| `research/internal/sea12/run_gepa_sea12.py` | `SEA12ProgressTracker` | Simpler, custom events |
| `cookbooks/demos/banking77/run_banking77_demo.py` | `Banking77DemoTracker` | Result-focused |
| `cookbooks/demos/banking77/run_banking77_demo_prod.py` | (reuses Banking77DemoTracker) | Imports from local |
| `cookbooks/dev/blog_posts/langprobe/integrations/learning_curve_tracker.py` | `LearningCurveTracker` | Different purpose - checkpoints |
| `synth_ai/cli/local/experiment_queue/status_tracker.py` | `parse_progress_from_output` | Regex-based, fragile |

## Pattern Analysis

### Smart Patterns (Keep)

1. **`GEPAProgressTracker` (research/run_gepa_banking77_dev.py)**
   - `all_candidates: list[dict]` - Stores ALL candidates for later analysis
   - `pareto_candidates: list[dict]` - Subset of pareto-optimal
   - `_store_candidate()` method - Consistent storage
   - tqdm progress bars with good formatting
   - Handles masked event types (`[MASKED]` → `gepa`)

2. **`Banking77DemoTracker` (cookbooks/demos/banking77)**
   - `pareto_history` - Tracks frontier changes over time
   - `baseline_prompt` - Stores full baseline for comparison
   - `baseline_instance_scores` - Per-seed scores
   - `save_comprehensive_results()` - Separate function for result saving
   - Separation of tracking vs saving

3. **`LearningCurveTracker` (langprobe)**
   - Checkpoint-based recording (10%, 25%, 50%, 75%, 100%)
   - Clean dataclasses (`LearningCurve`, `Checkpoint`)
   - CSV + JSON export
   - Could be integrated as an optional feature

4. **`SEA12ProgressTracker` (research/internal/sea12)**
   - Simple, focused, doesn't try to do everything
   - Custom event types (`baseline_complete`, `rollout_complete`, `generation_complete`)
   - Clean logging without tqdm noise

### Dumb Patterns (Kill)

1. **Copy-paste classes** - RedactleProgressTracker, StyleMatchingProgressTracker are 95% identical to GEPAProgressTracker. Only diff is the print banner.

2. **Regex parsing** (`status_tracker.py`) - Parsing progress from stdout is fragile and breaks when log format changes.

3. **Inconsistent event handling** - Each tracker handles different event types:
   - Some check `event_type == "prompt.learning.gepa.baseline"`
   - Some check `event_type.endswith(".baseline")`
   - Some check `"baseline" in event_type.lower()`

4. **Inline event parsing** - Logic duplicated in each `update_from_event()` instead of centralized.

5. **Tightly coupled terminal output** - Can't reuse tracker logic without also getting tqdm bars.

## Recommended Consolidation

### Core Classes

```python
# synth_ai/sdk/api/train/progress/events.py
class EventParser:
    """Centralized SSE event parsing with normalization."""

    @staticmethod
    def normalize_type(event_type: str) -> str:
        """Normalize event types (handle [MASKED], variants, etc.)"""
        # Replace [MASKED] with gepa
        event_type = event_type.replace("[MASKED]", "gepa")
        return event_type

    @staticmethod
    def is_event(event_type: str, *patterns: str) -> bool:
        """Check if event matches any pattern."""
        normalized = EventParser.normalize_type(event_type)
        for pattern in patterns:
            if pattern in normalized or normalized.endswith(pattern):
                return True
        return False

    @classmethod
    def parse(cls, event: dict) -> ParsedEvent:
        """Parse raw SSE event into typed event."""
        event_type = cls.normalize_type(event.get("type", ""))
        data = event.get("data", {}) if isinstance(event.get("data"), dict) else {}

        if cls.is_event(event_type, ".baseline"):
            return BaselineEvent(...)
        elif cls.is_event(event_type, ".candidate.evaluated", ".proposal.scored"):
            return CandidateEvent(...)
        elif cls.is_event(event_type, ".frontier_updated"):
            return FrontierEvent(...)
        elif cls.is_event(event_type, ".progress"):
            return ProgressEvent(...)
        elif cls.is_event(event_type, ".complete"):
            return CompleteEvent(...)
        else:
            return GenericEvent(event_type, data)
```

### Display Options

```python
class DisplayMode(Enum):
    SILENT = "silent"          # No output
    MINIMAL = "minimal"        # One-liners only
    TQDM = "tqdm"              # tqdm progress bars
    RICH = "rich"              # Rich console (future)

tracker = GEPAProgressTracker(
    display_mode=DisplayMode.TQDM,  # Or SILENT for programmatic use
    env_name="banking77",           # For banner customization
    max_rollouts=500,
    max_trials=100,
)
```

### Result Saving

Keep `save_comprehensive_results()` as a separate module:

```python
# synth_ai/sdk/api/train/progress/results.py
def save_results(
    tracker: GEPAProgressTracker,
    output_dir: Path,
    *,
    include_raw_events: bool = False,
    include_rollout_samples: bool = True,
) -> dict[str, Path]:
    """Save all result files."""
    files = {}
    files["candidates"] = save_candidates(tracker, output_dir)
    files["pareto_history"] = save_pareto_history(tracker, output_dir)
    files["seed_analysis"] = save_seed_analysis(tracker, output_dir)
    files["summary"] = save_summary(tracker, output_dir)
    return files
```

## Priority Order

1. **EventParser** - Centralize event normalization (fixes inconsistent handling)
2. **Typed events** - BaselineEvent, CandidateEvent, etc. (type safety)
3. **GEPAProgressTracker** - Unified tracker with display modes
4. **save_results()** - Modular result saving
5. **Kill copy-paste classes** - Update all demos to use unified tracker
