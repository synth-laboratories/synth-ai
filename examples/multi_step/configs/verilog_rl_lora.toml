[algorithm]
type = "online"
method = "policy_gradient"
variety = "gspo"

[services]
task_url = "https://synth-laboratories--grpo-verilog-task-app-fastapi-app-dev.modal.run"
judge_url = "https://synth-backend-dev-docker.onrender.com/api"

[compute]
gpu_type = "H200"
gpu_count = 2
nodes = 1

[topology]
type = "single_node_split"
gpus_for_vllm = 1
gpus_for_training = 1
gpus_for_ref = 0
tensor_parallel = 1

[vllm]
tensor_parallel_size = 1
max_model_len = 24576

[reference]
placement = "none"

[model]
base = "Qwen/Qwen3-8B"
trainer_mode = "lora"
label = "verilog-rl-lora-qwen8b"

[lora]
r = 16
alpha = 32
dropout = 0.05
target_modules = [ "all-linear",]

[rollout]
env_name = "verilog"
max_turns = 6
episodes_per_batch = 4
policy_name = "verilog-designer"
max_concurrent_rollouts = 8
batches_per_step = 2
ops = [ "agent", "env",]

[evaluation]
instances = 16
every_n_iters = 10
seeds = [ 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15,]

[training]
num_epochs = 1
iterations_per_epoch = 5
gradient_accumulation_steps = 1
max_accumulated_minibatch = 1
max_turns = 15
batch_size = 4
group_size = 4
learning_rate = 5e-5
log_interval = 1
weight_sync_interval = 1
event_rewards_kind = "unique"
async_semaphore_max = 20
step_rewards_enabled = true
step_rewards_mode = "decision_stepwise"
step_rewards_indicator_lambda = 0.5
step_rewards_beta = 0.0
step_rewards_strategy = "consistent"

[judge]
enabled = true

[rollout.env_config]
difficulty = "medium"

[rollout.policy_config]
provider = "openai"
model = "Qwen/Qwen3-8B"
temperature = 0.2
max_tokens = 4096

[training.weight_sync]
enable = true
targets = [ "policy",]
mode = "direct"
direct = true
verify_every_k = 0

[judge.reward_blend]
env = 0.3
event = 0.3
outcome = 0.4

[judge.options]
event = true
outcome = true
provider = "openai"
model = "openai/gpt-oss-120b"
rubric_id = "verilog/bundle@v1"
timeout_s = 45

[rollout.env_config.step_rewards]
enabled = true
mode = "decision_stepwise"
strategy = "consistent"
indicator_lambda = 0.5
step_beta = 0.0

[judge.options.weights]
process = 0.1
reasoning = 0.2
progress = 0.3
outcome = 0.4

[judge.options.rubric_overrides.event]
goal_text = "      Evaluate each Verilog design decision for compilation success and process efficiency.\n      High scores for successful compilation and strategic tool usage.\n      Penalize unnecessary operations and compilation failures."
aggregation = "weighted_sum"
[[judge.options.rubric_overrides.event.criteria]]
id = "process.compilation_success"
weight = 0.7
scale = "bounded"
description = "Return 1.0 when compilation succeeds cleanly, 0.5 for warnings, 0.0 for errors"

[[judge.options.rubric_overrides.event.criteria]]
id = "process.design_iterations"
weight = 0.3
scale = "bounded"
description = "Reward efficient write→compile→simulate workflow, penalize redundant operations"

[judge.options.rubric_overrides.outcome]
goal_text = "      Evaluate the final Verilog implementation for correctness and quality.\n      High scores for working designs that pass all tests with good code quality."
aggregation = "weighted_sum"
[[judge.options.rubric_overrides.outcome.criteria]]
id = "outcome.tests_passed"
weight = 0.8
scale = "binary"
description = "Full credit when all tests pass, partial credit for some tests passing"

[[judge.options.rubric_overrides.outcome.criteria]]
id = "outcome.design_quality"
weight = 0.2
scale = "bounded"
description = "Code clarity, proper documentation, and efficient design patterns"

