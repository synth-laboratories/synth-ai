[algorithm]
type = "online"
method = "policy_gradient"
variety = "gspo"

[services]
task_url = "https://YOUR-MODAL-TASK-APP.modal.run"
judge_url = "https://synth-backend-dev-docker.onrender.com/api"

[compute]
gpu_type = "H200"
gpu_count = 4

[topology]
type = "single_node_split"
gpus_for_vllm = 2
gpus_for_training = 2
gpus_for_ref = 0
tensor_parallel = 2

[vllm]
tensor_parallel_size = 2
max_model_len = 4096

[reference]
placement = "none"

[model]
base = "Qwen/Qwen3-Coder-30B-A3B-Instruct"
trainer_mode = "lora"
label = "crafter-rl-stepwise-hosted-judge"

[lora]
r = 16
alpha = 32
dropout = 0.05
target_modules = [ "all-linear",]

[rollout]
env_name = "crafter"
max_turns = 10
episodes_per_batch = 2
policy_name = "crafter-react"
max_concurrent_rollouts = 8
batches_per_step = 2
ops = [ "agent", "env",]
rubric_rewards_only = true

[evaluation]
instances = 16
every_n_iters = 10
seeds = [ 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15,]

[training]
num_epochs = 1
iterations_per_epoch = 5
gradient_accumulation_steps = 1
max_accumulated_minibatch = 1
max_turns = 10
batch_size = 4
group_size = 4
learning_rate = 5e-5
log_interval = 1
weight_sync_interval = 1
event_rewards_kind = "unique"
async_semaphore_max = 4
step_rewards_enabled = true
step_rewards_mode = "decision_stepwise"
step_rewards_indicator_lambda = 1.0
step_rewards_beta = 0.0
step_rewards_strategy = "consistent"

[rubric]
enabled = true

[rollout.env_config]
difficulty = "easy"

[rollout.policy_config]
temperature = 0.2
top_p = 0.95
max_tokens = 512

[training.weight_sync]
enable = true
targets = [ "policy",]
mode = "direct"
direct = true
verify_every_k = 0

[rubric.weights]
env = 0.2
event = 0.4
outcome = 0.4

[judge.options]
event = true
outcome = true
provider = "openai"
model = "openai/gpt-oss-120b"
rubric_id = "crafter/bundle@v1"
timeout_s = 45

[rollout.env_config.step_rewards]
enabled = true
mode = "decision_stepwise"
strategy = "consistent"
indicator_lambda = 1.0
step_beta = 0.0

[judge.options.weights]
process = 0.05
reasoning = 0.15
progress = 0.3
outcome = 0.5

[judge.options.rubric_overrides.event]
goal_text = "Treat each decision as a check for new Crafter achievements.\nAward the top score only when the log shows a fresh achievement unlock or an immediately verifiable deterministic completion.\nKeep otherwise useful setup actions in a narrow low band so non-achievement turns stay near zero."
aggregation = "weighted_sum"
[[judge.options.rubric_overrides.event.criteria]]
id = "progress.unique_achievements"
weight = 0.9
scale = "binary"
description = "Return 1 when this decision explicitly unlocks a brand-new Crafter achievement (inventory or status text confirms it this turn). Otherwise return 0."

[[judge.options.rubric_overrides.event.criteria]]
id = "process.intent_alignment"
weight = 0.1
scale = "bounded"
description = "Use at most 0.3 to acknowledge tightly coupled setup that finishes the last prerequisite; keep ≤0.1 when the agent only repositions or gathers without an imminent unlock."

[judge.options.rubric_overrides.outcome]
goal_text = "Summarise the episode outcome in relation to Crafter’s win condition:\nsurvive, accumulate resources, and craft advanced tools or structures.\nHighlight notable achievements, safety failures, and preparedness for future exploration."
aggregation = "weighted_sum"
[[judge.options.rubric_overrides.outcome.criteria]]
id = "outcome.goal_completion"
weight = 0.6
scale = "binary"
description = "Full credit when the agent ends with strong survival metrics and a clear crafted milestone (e.g., iron tools, furnace)."

[[judge.options.rubric_overrides.outcome.criteria]]
id = "outcome.achievement_depth"
weight = 0.4
scale = "bounded"
description = "Partial credit for intermediate achievements (saplings, wood/stone tools) that set up future success."

