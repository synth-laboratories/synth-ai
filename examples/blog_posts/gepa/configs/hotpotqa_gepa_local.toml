# GEPA Prompt Learning for HotpotQA
# Local backend configuration targeting the HotpotQA task app.

[prompt_learning]
algorithm = "gepa"
task_app_url = "http://127.0.0.1:8110"
task_app_id = "hotpotqa"

# Seeds for online evaluation (episode IDs)
evaluation_seeds = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]

# Held-out pool used for final evaluation
test_pool = [10, 11, 12, 13, 14, 15, 16, 17, 18, 19]

[prompt_learning.initial_prompt]
id = "hotpotqa_chain"
name = "HotpotQA Multi-Hop Reasoning"

[[prompt_learning.initial_prompt.messages]]
role = "system"
pattern = "You are a research assistant that answers multi-hop questions. Use the provided supporting passages to reason out the final answer. Reply with the format:\nAnswer: <short answer>\nSupport: <brief justification referencing the passages>."
order = 0

[[prompt_learning.initial_prompt.messages]]
role = "user"
pattern = "Question: {question}\n\nPassages:\n{context}\n\nProvide the final answer and cite the relevant supporting facts."
order = 1

[prompt_learning.initial_prompt.wildcards]
question = "REQUIRED"
context = "REQUIRED"

[prompt_learning.policy]
model = "openai/gpt-oss-20b"
provider = "groq"
inference_url = "https://api.groq.com/openai/v1"
temperature = 0.0
max_completion_tokens = 512
policy_name = "hotpotqa-gepa"

[prompt_learning.gepa]
env_name = "hotpotqa"
initial_population_size = 24
num_generations = 15
mutation_rate = 0.35
crossover_rate = 0.55
selection_pressure = 1.0
minibatch_size = 8
pareto_set_size = 24
feedback_fraction = 0.5
children_per_generation = 12
patience_generations = 5
rollout_budget = 600
archive_size = 36
pareto_eps = 1e-6
max_concurrent_rollouts = 24
mutation_llm_model = "openai/gpt-oss-20b"
mutation_llm_provider = "groq"
mutation_llm_inference_url = "https://api.groq.com/openai/v1"
