# GEPA Prompt Learning for the Banking77 Two-Stage Pipeline (Test/Production)
# This config optimizes both query_analyzer and classifier stages using genetic evolution

[prompt_learning]
algorithm = "gepa"
task_app_url = "https://synth-laboratories-dev--synth-banking77-pipeline-web-web.modal.run"
task_app_id = "banking77-pipeline"

[prompt_learning.initial_prompt]
id = "banking77_pipeline_baseline"
name = "Banking77 Pipeline Baseline"

[[prompt_learning.initial_prompt.messages]]
role = "system"
pattern = "Pipeline placeholder message. Actual stage instructions are provided via metadata.pipeline_modules."
order = 0

[prompt_learning.initial_prompt.metadata]
# Define the stages in the pipeline
pipeline_modules = [
  { name = "query_analyzer", stage_id = "query_analyzer", module_id = "query_analyzer", instruction_text = "You analyze customer banking queries to extract key information. Identify the main topic and any specific details mentioned.", few_shots = [] },
  { name = "classifier", stage_id = "classifier", module_id = "classifier", instruction_text = "You are an expert banking assistant that classifies customer queries into banking intents. Given a customer message, respond with exactly one intent label from the provided list using the `banking77_classify` tool.", few_shots = [] }
]

[prompt_learning.policy]
inference_mode = "synth_hosted"
model = "openai/gpt-oss-20b"
provider = "groq"
temperature = 0.0
max_completion_tokens = 128
policy_name = "banking77-pipeline"

[prompt_learning.env_config]
pool = "train"

# GEPA-specific configuration
[prompt_learning.gepa]
env_name = "banking77_pipeline"
rng_seed = 42
proposer_type = "dspy"

# Multi-stage module configuration (instruction-only for GEPA)
# Each module defines constraints for its stage
[[prompt_learning.gepa.modules]]
module_id = "query_analyzer"
max_instruction_slots = 2
max_tokens = 512
allowed_tools = []  # Analyzer doesn't use tools

[[prompt_learning.gepa.modules]]
module_id = "classifier"
max_instruction_slots = 3
max_tokens = 1024
allowed_tools = ["banking77_classify"]  # Classifier must use this tool

# Rollout configuration
[prompt_learning.gepa.rollout]
budget = 2000
max_concurrent = 20
minibatch_size = 8

# Evaluation configuration
[prompt_learning.gepa.evaluation]
seeds = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]
validation_seeds = [15, 16, 17, 18, 19]
test_pool = [40, 41, 42, 43, 44, 45, 46, 47, 48, 49]

# Mutation configuration (LLM-guided)
[prompt_learning.gepa.mutation]
rate = 0.3
llm_model = "llama3-groq-70b-8192-tool-use-preview"
llm_provider = "groq"

# Population/evolution configuration
[prompt_learning.gepa.population]
initial_size = 20
num_generations = 10
children_per_generation = 5
crossover_rate = 0.5
selection_pressure = 1.0
patience_generations = 3

# Archive/Pareto configuration
[prompt_learning.gepa.archive]
size = 64
pareto_set_size = 64
pareto_eps = 1e-6
feedback_fraction = 0.5

# Token/budget configuration
[prompt_learning.gepa.token]
max_limit = 50000
counting_model = "gpt-4"
enforce_pattern_limit = true
max_spend_usd = 200.0

