# Configuration for synth_mipro parallel comparison runs
# This file is the source of truth for which benchmarks + models + configs get run
#
# MODES AVAILABLE:
#   - "dspy": Our backend optimizer with dspy proposer (multi-step reasoning)
#   - "synth": Our backend optimizer with synth proposer (multi-step reasoning)
#
# BENCHMARK COVERAGE:
#   - Banking77: dspy mode
#   - HeartDisease: dspy mode
#   - Pupa: dspy mode
#   - Hotpotqa: dspy mode
#
# CONFIGURATION NOTES:
#   - All benchmarks have bootstrap_train_seeds, online_pool, test_pool, and reference_pool configured
#   - All benchmarks have enable_task_app_metadata: true for code extraction (needed for multi-step reasoning)
#   - proposer_mode is set to "dspy" for all benchmarks
#   - Rollout limits match GEPA dspy mode benchmarks exactly for fair comparison:
#     * Banking77: 500 rollouts
#     * HeartDisease: 500 rollouts
#     * Pupa: 300 rollouts
#     * Hotpotqa: 100 rollouts
#   - Seed pools match GEPA train_seeds/val_seeds:
#     * bootstrap_train_seeds = GEPA train_seeds
#     * val_seeds = GEPA val_seeds (used for validation, matches reference_pool)
#     * reference_pool = GEPA val_seeds (legacy name, same as val_seeds)
#     * online_pool = same as bootstrap_train_seeds (for online evaluation during optimization)

benchmarks:
  # Banking77 - DSPy mode (multi-step reasoning)
  # Matches GEPA banking77_dspy: rollout_limit=500, train_seeds=[0-24], val_seeds=[50-149]
  banking77_dspy:
    run: true
    config_path: "examples/blog_posts/mipro/configs/banking77_mipro_local.toml"
    rollout_limit: 500
    model:
      provider: "groq"
      model: "llama-3.1-8b-instant"
    proposer_mode: "dspy"
    "prompt_learning.mipro.enable_task_app_metadata": true
    "prompt_learning.mipro.bootstrap_train_seeds": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24]
    "prompt_learning.mipro.online_pool": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24]
    "prompt_learning.mipro.reference_pool": [50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149]
    "prompt_learning.mipro.val_seeds": [50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149]
    # Note: test_pool is defined in the TOML file as [40-49] (no overlap with reference_pool)
  
  # HeartDisease - DSPy mode (multi-step reasoning)
  # Matches GEPA heartdisease_dspy: rollout_limit=500, train_seeds=[0-29], val_seeds=[30-79]
  heartdisease_dspy:
    run: true
    config_path: "examples/blog_posts/langprobe/task_specific/heartdisease/heartdisease_gepa.toml"
    rollout_limit: 500
    model:
      provider: "groq"
      model: "openai/gpt-oss-20b"
    proposer_mode: "dspy"
    "prompt_learning.mipro.enable_task_app_metadata": true
    "prompt_learning.mipro.bootstrap_train_seeds": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29]
    "prompt_learning.mipro.online_pool": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29]
    "prompt_learning.mipro.reference_pool": [30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79]
    "prompt_learning.mipro.val_seeds": [30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79]
    "prompt_learning.mipro.test_pool": [80, 81, 82, 83, 84, 85, 86, 87, 88, 89]
  
  # Pupa - DSPy mode (multi-step reasoning)
  # Matches GEPA pupa_dspy: rollout_limit=300, train_seeds=[0-49], val_seeds=[50-79]
  pupa_dspy:
    run: true
    config_path: "examples/blog_posts/langprobe/task_specific/pupa/pupa_gepa.toml"
    rollout_limit: 300
    model:
      provider: "groq"
      model: "openai/gpt-oss-120b"
    proposer_mode: "dspy"
    "prompt_learning.mipro.enable_task_app_metadata": true
    "prompt_learning.mipro.bootstrap_train_seeds": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49]
    "prompt_learning.mipro.online_pool": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49]
    "prompt_learning.mipro.reference_pool": [50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79]
    "prompt_learning.mipro.val_seeds": [50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79]
    "prompt_learning.mipro.test_pool": [80, 81, 82, 83, 84, 85, 86, 87, 88, 89]
  
  # Hotpotqa - DSPy mode (multi-step reasoning)
  # Matches GEPA hotpotqa_dspy: rollout_limit=100, train_seeds=[0-49], val_seeds=[50-79]
  hotpotqa_dspy:
    run: true
    config_path: "examples/blog_posts/langprobe/task_specific/hotpotqa/hotpotqa_gepa.toml"
    rollout_limit: 100
    model:
      provider: "groq"
      model: "llama-3.3-70b-versatile"
    proposer_mode: "dspy"
    "prompt_learning.mipro.enable_task_app_metadata": true
    "prompt_learning.mipro.bootstrap_train_seeds": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49]
    "prompt_learning.mipro.online_pool": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49]
    "prompt_learning.mipro.reference_pool": [50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79]
    "prompt_learning.mipro.val_seeds": [50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79]
    "prompt_learning.mipro.test_pool": [80, 81, 82, 83, 84, 85, 86, 87, 88, 89]

defaults:
  time_limit_seconds: 600
  max_trials: 1000  # Increased to allow more trials (each trial can involve multiple rollouts)
  max_cost_usd: 10.0

